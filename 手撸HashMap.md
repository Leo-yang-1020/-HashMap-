#### 个人踩坑和可以提升的点

1. key和value均为String
    2.bucket为实际的存储

2. 小心key可能为null，当key为null时，其存储在数组中下标为0的位置，如果出现第二个entry的key也是null,则会替换之前的key为null的entry,只能由一个key为null，但可以有多个value为null。

4. 可以加入泛型，hashmap的key value可以是丰富多样的，而非定死的String，String

5. 1.8引进的红黑树，这个我不想写了23333，李姐下就好

6. jdk1.7是先判断是否扩容，再插入，jdk1.8是先插入，再判断是否扩容

7. jdk1.7和jdk1,8对于扩容时元素的重新hash也不同，1.7是直接重新hash。jdk1.8并不这样，采用了效率更高的方法：

  这里简单讲一下：

  由于扩容时将数组扩大为原来的2倍：

  假如原来的长度为16，则length-1=15：01111

  现在长度为32，length-1=31: 011111

  因此，只会出现两种情况：(可以先看下面将的hash算法和hash散列得坐标的算法再看这里)

  若原来的hash的第五位是0，则和length-1进行与运算时，得到的下标不变。

  若原来的hash的第五位是1，则和length-1进行与运算时，得到的下标比原来大16(旧数组的容量)

  这样，我们可以判断原hash即可，不必全部重新hash

8. 链表插入从头插变成尾插(好像是防止线程安全的问题形成环形链表，具体等会再看)

#### 一些自己的思考总结

1. put方法实现的流程

   首先对K进行hash算法，得到Bucket的坐标。如果此时桶为空，即不存在哈希冲突问题，就直接将其插入，如果存在Hash冲突，则对比Key，如果Key相同，说明是替换操作，替换即可，如果Key不同，再判断结点类型：如果是红黑树结点，说明已经转化为红黑树了，就直接按照红黑树插入的规则插入。如果是链表结点，那么使用尾插法插入。插入后判断是否需要转化为红黑树。最后，判断节点总数是否超过阈值以决定是否扩展。

2. hashmap的一些最基本的特性（使用者关注）
   - hash表底层就是一个bucket数组，数组下标由hash函数实现，每一个key可以得到一个下标。哈希冲突由拉链法解决。而bucket由两种表现形式，当数量小于等于8时，为链表存储，jdk1.8后，便引入了红黑树，避免当多个key集中一个下标时，hash表退化成为链表，失去去特性。
   - hash表通过键值对实现了快速存取，key可以为Null，但是key不能重复，重复put会使得键值对更新

3. hashmap的hashcode值的计算以及为啥，源码中hashmap的初始长度为16？(好像我们是4来着？)反正都是2的幂，而不是一些10，20这样的整十。

   这里先康康运总给我们写的hash函数：

   key == null ? 0 : Math.abs(key.hashCode()) % bucketLen

   这里体现的有：

   1. 对key为null的特殊处理，存放在下标为0的地方
   2. 对于一般的key，通过hashcode取绝对值后再mod，mod是为了避免下标越界

   而实际的源码实现：竟然没有用到mod!!

   ```java
    static final int hash(Object key) {
           int h;
           return (key == null) ? 0 : (h = key.hashCode()) ^ (h >>> 16);
       }
   ```

   我们可以发现，对于null值的处理和运总写的hash函数一样，但是呢，普通的hash却要复杂一些，这里是先求key的hashcode，要理解，必须要看懂之后的位运算，要看懂，必须先理解位运算，补码，原码等知识。

   4. 对于扩容，链表转化为红黑树的一些小知识:

      扩容，实际上存在两个参数：loadFactor(装载因子)乘capacity(容量)，loadFactor一般默认为0.75,装填因子实际就是n/m，需要控制在在0.6到0.9之间，java选择的中间数0.75。

      举个例子：当前cap=16,loadFactor为0.75,现在有12个元素，现在即将插入一个新元素，于是乎，就会扩容翻倍，cap变为32，但是一般只有扩容，没有缩容。

      另外，链表转化为红黑树除了有bucket中元素超过8个以外，还需要有：cap>=64，否则即使元素超过个个也不会转化

   ##### java位运算知识的补充

   \>> ,\<< ，\>>>这些符号的意义？

   java中的数值由二进制表示时，都是用**补码**表示，一般为32bit

   \<<,\>>分别代表左移和右移，

   \<<表示左移，无论正负数，低位补0

   \>>表示右移，该数为正，高位补0，该数为负补

   \>>> 表示无符号右移，若该数为正，则高位补0，若该数为负，右移后高位同样补0：这样就会使得只要无符号右移了，数一定是正数

   java的 & (与)| (或)^ (异或)~(非)运算,这些好像和python是一样的,具体可以查查

   我们知道了这些原理后，再看源代码，就会慢慢李姐了..

   ```java
   (h = key.hashCode()) ^ (h >>> 16)
   ```

   这里我们不难发现，h右移16位，得到的实际上是hashcode的高十六位，由hashcode和高十六位异或运算得到。为啥子不直接用key的hashcode就完事，而是整这么多复杂的东东呢？

   首先，hashcode得到的是一个32位的二进制数

   **因为数组位置的确定用的是与运算（下面有散列的方法），仅仅最后四位有效，设计者将key的哈希值与高16为做异或运算使得在做&运算确定数组的插入位置时，此时的低位实际是高位与低位的结合，增加了随机性，也就是混合高位低位，减少了哈希碰撞的次数。**

   异或运算，当有一个值改变，最终异或的结果都会改变，这样也加大了随机性。

   个人感觉这个比较抽象，主要是理解到我们所做的hash函数的一切只有一个目的：使得散列尽可能均匀，减少hash冲突。

   ```java
   hash散列的方法：hash&(length-1),即对得到的hash值与length-1取与即可
   ```

   1.  为啥和length-1取与，而不是length？

      ```
      这个是因为数组下标从0到length-1有效，而我们取与操作得到的值不可能大于length-1,因此选择length-1取与
      ```

   2. 为啥选择取与，而不是求mod？

      ```
      无他，一切皆为二进制，快就完事了,你求mod还要转换为10进制一顿操作，取与直接二进制开算，效率no.1
      ```

   3. **那，为啥我们设计容量总是2^n，而不是其他的？**

      ```
      首先，为2的幂的数，存在一个规律，就是其二进制表达一定一定是第一位为1，末尾为0
      4: 100
      8:1000
      16:10000
      这个好像不用我说大家也都能知道....
      那么其减1后(length-1)，会出现什么呢？那就是：首位为0，其余均为1
      4-1=3：011
      8-1=7:0111...
      我们设计这么多的目的都是为了由key产生的数，必须要比length小，且越均匀越好。
      重点来了！！！
      我们产生坐标使用的是与运算，1和任何数进行与运算，其结果都取决于另一个数，这样，当length为2的幂时，length-1与和任何数进行与运算，得到的坐标，和length-1本身关系无关
      举个反例帮助解释：
      假设我们长度不取2的幂，随便取一个15
      15-1=14： 1110 这个数和任何数取与运算时，得到的坐标的最后一位一定是0 因为0和任何数取与都是0，这样就使得hash散列并不均匀。。。
      其实大家如果学了计网的掩码的概念，理解这个也就很轻松啦
      ```

      4. 关于线程的安全问题

         首先，HashMap线程是不安全的。解决线程安全的问题的方法很多

         比如我们最简单的方法：无脑加synchronize，我们的被淘汰的老朋友HashTable也就是这样做的，修改数据时锁住整个HashTable，线程安全了，但是效率低到离谱。

         ConcurrentHashMap采用一种锁分段的技术(jdk1.7),首先将数据分成一段一段的存储，然后给每一段数据配一把锁，当一个线程占用锁访问其中一个段数据的时候，其他段的数据也能被其他线程访问。 

         ConcurrentHashMap提供了与Hashtable和SynchronizedMap不同的锁机制。Hashtable中采用的锁机制是一次锁住整个hash表，从而在同一时刻只能由一个线程对其进行操作；而ConcurrentHashMap中则是一次锁住一个桶。

         jdk1.8又采用了CAS+synchronized。

         **这个分段锁我没有自己实现，所以只是纸上谈兵(别骂了）**

      5. 为啥不直接上红黑树

         其实Hash冲突也不是那么频繁，红黑树的插入需要左旋，右旋，变色等等骚操作来保持平衡，数量小于8时根本不需要用到红黑树

      6. 还有一些LinkedMap,TreeMap,HashTable，这些和HashMap的区别

         LinkedHashMap维护了一个链表，保存了插入的顺序，用迭代器遍历时先插入的元素先取到，遍历速度比HashMap慢：用于输出顺序和输入顺序相同的情况

         TreeMap实现了SortMap接口，能够把保存的记录根据键值排序：用于需要按自然顺序或自定义顺序遍历键的情况

         HashTable线程安全，但是key和value不能为null

关于该Lab使用到的数据结构的问题：

二叉搜索树的中序遍历就是一个递增的序列

需要在a的基础上完成：

完成Bst的编写，完成GlimmerHashMap的完善。

对于二叉搜索树（别忘记key和value均可以为null）：

**插入操作**：（这里需要注意的就是对与key为null的点的处理）直接递归插，和一般的做法比较像，因为二叉搜索树需要有比较操作，所以我们需要确定我们的比较算法：

如果没有key为null的情况就非常简单，但是key可能为null，我们采用的compareTo比较字符串大小必须要小心字符串为空的情况，所以要分类。

**删除操作**：好像比二叉平衡树简单一些，分类讨论一下就行。

如果要删除结点的左右孩子都有，则：

找到左子树的最大值结点，也就是要删除结点的直接前驱结点s,

之后，把要删除的结点的data替换为直接前驱结点s，再删除直接前驱结点，并且把s的父节点的右结点替换为s的左结点(s没有右结点)

**发散一下：LeetCode109:有序链表转化为平衡的二叉搜索树，这个可以顺便帮助理解二叉搜索树和二叉平衡搜索树(无聊刷到的）**

**思考** ：二叉搜索树真的够好吗？倘若原链表就是一个有序的链表，形成的二叉搜索树会产生“倾斜”，也就是其查询的时间复杂度又回到了O(n)，和链表相同，因此，为了改进，我们可以进一步，使用二叉平衡搜索树AVL  （源码使用的是红黑树，红黑树是一种特殊的AVL树且应用非常广泛，但是学习红黑树前先撸出二叉搜索树吧）

